/**
 * AI Content Service
 *
 * Servi√ßo para gera√ß√£o e otimiza√ß√£o de conte√∫do usando IA
 * Suporta m√∫ltiplos providers: OpenAI, Claude (Anthropic), Gemini (Google)
 */

import OpenAI from 'openai';
import Anthropic from '@anthropic-ai/sdk';

interface GenerateSuggestionsParams {
  content?: string;
  platform: string;
  tone?: string;
  niche?: string;
  language?: string;
}

interface OptimizeContentParams {
  content: string;
  platform: string;
  goal?: string;
  targetAudience?: string;
  language?: string;
}

interface AIResponse {
  success: boolean;
  suggestions?: string[];
  optimizedContent?: string;
  improvements?: string[];
  error?: string;
}

class AIContentService {
  private provider: 'openai' | 'anthropic' | 'gemini';
  private openai: OpenAI | null = null;
  private anthropic: Anthropic | null = null;

  constructor() {
    // Inicializar OpenAI se a key existir
    if (process.env.OPENAI_API_KEY) {
      this.openai = new OpenAI({
        apiKey: process.env.OPENAI_API_KEY
      });
      console.log('‚úÖ OpenAI GPT-4 client initialized');
    }

    // Inicializar Anthropic se a key existir
    if (process.env.ANTHROPIC_API_KEY) {
      this.anthropic = new Anthropic({
        apiKey: process.env.ANTHROPIC_API_KEY
      });
      console.log('‚úÖ Anthropic Claude client initialized');
    }

    // Definir provider padr√£o (prioridade: OpenAI > Anthropic)
    if (this.openai) {
      this.provider = 'openai';
      console.log('üéØ Provider padr√£o: OpenAI GPT-4 Turbo');
    } else if (this.anthropic) {
      this.provider = 'anthropic';
      console.log('üéØ Provider padr√£o: Anthropic Claude 3.5 Sonnet');
    } else {
      this.provider = 'openai'; // Fallback para mock
      console.log('‚ö†Ô∏è Nenhuma API key configurada - usando respostas mock');
    }
  }

  /**
   * Gera sugest√µes de conte√∫do para redes sociais
   */
  async generateSuggestions(params: GenerateSuggestionsParams): Promise<AIResponse> {
    try {
      const { content, platform, tone = 'profissional', niche, language = 'portugu√™s' } = params;

      // Monta o prompt
      const prompt = this.buildSuggestionsPrompt(content, platform, tone, niche, language);

      console.log('ü§ñ Gerando sugest√µes com IA...');
      console.log('Platform:', platform);
      console.log('Tone:', tone);

      // Chama a IA
      const suggestions = await this.callAI(prompt);

      console.log('‚úÖ Sugest√µes geradas:', suggestions.length);

      return {
        success: true,
        suggestions
      };

    } catch (error: any) {
      console.error('‚ùå Erro ao gerar sugest√µes:', error);
      return {
        success: false,
        error: error.message || 'Erro ao gerar sugest√µes',
        suggestions: this.getFallbackSuggestions(params.platform)
      };
    }
  }

  /**
   * Otimiza conte√∫do existente
   */
  async optimizeContent(params: OptimizeContentParams): Promise<AIResponse> {
    try {
      const { content, platform, goal = 'engajamento', targetAudience, language = 'portugu√™s' } = params;

      // Monta o prompt
      const prompt = this.buildOptimizationPrompt(content, platform, goal, targetAudience, language);

      console.log('ü§ñ Otimizando conte√∫do com IA...');
      console.log('Platform:', platform);
      console.log('Goal:', goal);

      // Chama a IA
      const result = await this.callAI(prompt);

      // Separa conte√∫do otimizado das melhorias sugeridas
      const optimizedContent = result[0] || content;
      const improvements = result.slice(1);

      console.log('‚úÖ Conte√∫do otimizado');

      return {
        success: true,
        optimizedContent,
        improvements
      };

    } catch (error: any) {
      console.error('‚ùå Erro ao otimizar conte√∫do:', error);
      return {
        success: false,
        error: error.message || 'Erro ao otimizar conte√∫do',
        optimizedContent: params.content,
        improvements: ['N√£o foi poss√≠vel otimizar o conte√∫do no momento']
      };
    }
  }

  /**
   * Monta prompt para gera√ß√£o de sugest√µes
   */
  private buildSuggestionsPrompt(
    content: string | undefined,
    platform: string,
    tone: string,
    niche: string | undefined,
    language: string
  ): string {
    let prompt = `Voc√™ √© um especialista em marketing de conte√∫do para redes sociais.\n\n`;

    prompt += `Gere 5 sugest√µes de posts para ${platform} em ${language}.\n\n`;

    if (niche) {
      prompt += `Nicho: ${niche}\n`;
    }

    if (content) {
      prompt += `Tema ou ideia base: ${content}\n`;
    }

    prompt += `Tom: ${tone}\n\n`;

    prompt += `Requisitos:\n`;
    prompt += `- Cada sugest√£o deve ser completa e pronta para postar\n`;
    prompt += `- Use emojis apropriados para o ${platform}\n`;
    prompt += `- Adapte o tamanho para a plataforma (${this.getPlatformCharLimit(platform)} caracteres)\n`;
    prompt += `- Inclua call-to-action quando apropriado\n`;
    prompt += `- Use hashtags relevantes (3-5 hashtags)\n\n`;

    prompt += `Retorne APENAS as 5 sugest√µes, uma por linha, sem numera√ß√£o ou texto adicional.`;

    return prompt;
  }

  /**
   * Monta prompt para otimiza√ß√£o de conte√∫do
   */
  private buildOptimizationPrompt(
    content: string,
    platform: string,
    goal: string,
    targetAudience: string | undefined,
    language: string
  ): string {
    let prompt = `Voc√™ √© um especialista em otimiza√ß√£o de conte√∫do para redes sociais.\n\n`;

    prompt += `Otimize o seguinte post para ${platform} em ${language}:\n\n`;
    prompt += `"${content}"\n\n`;

    prompt += `Objetivo: ${goal}\n`;

    if (targetAudience) {
      prompt += `P√∫blico-alvo: ${targetAudience}\n`;
    }

    prompt += `\nMelhorias desejadas:\n`;
    prompt += `- Aumentar ${goal}\n`;
    prompt += `- Manter autenticidade e naturalidade\n`;
    prompt += `- Usar emojis estrategicamente\n`;
    prompt += `- Adaptar para ${platform} (${this.getPlatformCharLimit(platform)} caracteres)\n`;
    prompt += `- Incluir hashtags relevantes\n`;
    prompt += `- Call-to-action efetivo\n\n`;

    prompt += `Retorne:\n`;
    prompt += `1. Primeira linha: O post otimizado\n`;
    prompt += `2. Linhas seguintes: 3-4 explica√ß√µes breves do que foi melhorado`;

    return prompt;
  }

  /**
   * Chama a IA com o provider configurado
   */
  private async callAI(prompt: string): Promise<string[]> {
    try {
      if (this.provider === 'openai' && this.openai) {
        return await this.callOpenAI(prompt);
      } else if (this.provider === 'anthropic' && this.anthropic) {
        return await this.callAnthropic(prompt);
      } else {
        // Fallback para mock
        console.log('‚ö†Ô∏è Usando resposta mock (sem API key configurada)');
        return this.getMockResponse();
      }
    } catch (error: any) {
      console.error('‚ùå Erro ao chamar IA:', error.message);
      return this.getMockResponse();
    }
  }

  /**
   * Chama OpenAI GPT-4
   */
  private async callOpenAI(prompt: string): Promise<string[]> {
    if (!this.openai) throw new Error('OpenAI client not initialized');

    console.log('ü§ñ Chamando OpenAI GPT-4...');

    const completion = await this.openai.chat.completions.create({
      model: 'gpt-4-turbo-preview',
      messages: [
        {
          role: 'system',
          content: 'Voc√™ √© um especialista em marketing de conte√∫do para redes sociais.'
        },
        {
          role: 'user',
          content: prompt
        }
      ],
      temperature: 0.8,
      max_tokens: 1000
    });

    const response = completion.choices[0]?.message?.content || '';

    // Divide a resposta em linhas (cada linha √© uma sugest√£o ou melhoria)
    const lines = response
      .split('\n')
      .map(line => line.trim())
      .filter(line => line.length > 0);

    console.log('‚úÖ OpenAI respondeu com', lines.length, 'linhas');

    return lines;
  }

  /**
   * Chama Anthropic Claude
   */
  private async callAnthropic(prompt: string): Promise<string[]> {
    if (!this.anthropic) throw new Error('Anthropic client not initialized');

    console.log('ü§ñ Chamando Anthropic Claude...');

    const message = await this.anthropic.messages.create({
      model: 'claude-3-5-sonnet-20241022',
      max_tokens: 1000,
      messages: [
        {
          role: 'user',
          content: prompt
        }
      ]
    });

    const response = message.content[0].type === 'text'
      ? message.content[0].text
      : '';

    // Divide a resposta em linhas
    const lines = response
      .split('\n')
      .map(line => line.trim())
      .filter(line => line.length > 0);

    console.log('‚úÖ Claude respondeu com', lines.length, 'linhas');

    return lines;
  }

  /**
   * Resposta mock para fallback
   */
  private getMockResponse(): string[] {
    return [
      'Conte√∫do otimizado com emojis ‚ú® e call-to-action! üöÄ #Marketing #SocialMedia',
      'Adicionado emojis relevantes para aumentar engajamento',
      'Inclu√≠do hashtags estrat√©gicas para alcance',
      'Melhorado call-to-action para incentivar intera√ß√£o'
    ];
  }

  /**
   * Retorna limite de caracteres por plataforma
   */
  private getPlatformCharLimit(platform: string): number {
    const limits: Record<string, number> = {
      twitter: 280,
      facebook: 63206,
      instagram: 2200,
      linkedin: 3000,
      tiktok: 2200
    };

    return limits[platform.toLowerCase()] || 2000;
  }

  /**
   * Retorna sugest√µes fallback em caso de erro
   */
  private getFallbackSuggestions(platform: string): string[] {
    return [
      `‚ú® Compartilhe sua experi√™ncia com nossos produtos! O que voc√™ achou? üí¨ #Experi√™ncia #Feedback`,
      `üöÄ Descubra como podemos ajudar voc√™ a alcan√ßar seus objetivos! Clique no link da bio üì≤ #Transforma√ß√£o #Sucesso`,
      `üí° Dica do dia: Pequenas a√ß√µes di√°rias levam a grandes resultados! Qual √© a sua meta de hoje? üéØ #Motiva√ß√£o #Crescimento`,
      `üéâ Novidades chegando! Fique atento √†s nossas pr√≥ximas atualiza√ß√µes üì¢ #Novidades #EmBreve`,
      `‚ù§Ô∏è Obrigado por fazer parte da nossa comunidade! Seu apoio significa tudo para n√≥s üôè #Gratid√£o #Comunidade`
    ];
  }
}

export const aiContentService = new AIContentService();
